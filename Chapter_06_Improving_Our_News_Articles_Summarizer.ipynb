{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YQVIcL2LWULJ"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain==0.0.208 openai==0.27.8 python-dotenv newspaper3k lxml_html_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDuYoCMhWW_x",
        "outputId": "263b5178-3454-4366-c1f7-250218342aae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "!echo \"OPENAI_API_KEY='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'\" > .env\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6rH09GpWyP_",
        "outputId": "5d68d461-2ba1-4090-9ba9-63d92406f109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Meta claims its new AI supercomputer will set records\n",
            "Text: Meta (formerly Facebook) has unveiled an AI supercomputer that it claims will be the world’s fastest.\n",
            "\n",
            "The supercomputer is called the AI Research SuperCluster (RSC) and is yet to be fully complete. However, Meta’s researchers have already begun using it for training large natural language processing (NLP) and computer vision models.\n",
            "\n",
            "RSC is set to be fully built in mid-2022. Meta says that it will be the fastest in the world once complete and the aim is for it to be capable of training models with trillions of parameters.\n",
            "\n",
            "“We hope RSC will help us build entirely new AI systems that can, for example, power real-time voice translations to large groups of people, each speaking a different language, so they can seamlessly collaborate on a research project or play an AR game together,” wrote Meta in a blog post.\n",
            "\n",
            "“Ultimately, the work done with RSC will pave the way toward building technologies for the next major computing platform — the metaverse, where AI-driven applications and products will play an important role.”\n",
            "\n",
            "For production, Meta expects RSC will be 20x faster than Meta’s current V100-based clusters. RSC is also estimated to be 9x faster at running the NVIDIA Collective Communication Library (NCCL) and 3x faster at training large-scale NLP workflows.\n",
            "\n",
            "A model with tens of billions of parameters can finish training in three weeks compared with nine weeks prior to RSC.\n",
            "\n",
            "Meta says that its previous AI research infrastructure only leveraged open source and other publicly-available datasets. RSC was designed with the security and privacy controls in mind to allow Meta to use real-world examples from its production systems in production training.\n",
            "\n",
            "What this means in practice is that Meta can use RSC to advance research for vital tasks such as identifying harmful content on its platforms—using real data from them.\n",
            "\n",
            "“We believe this is the first time performance, reliability, security, and privacy have been tackled at such a scale,” says Meta.\n",
            "\n",
            "(Image Credit: Meta)\n",
            "\n",
            "Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo. The next events in the series will be held in Santa Clara on 11-12 May 2022, Amsterdam on 20-21 September 2022, and London on 1-2 December 2022.\n",
            "\n",
            "Explore other upcoming enterprise technology events and webinars powered by TechForge here.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from newspaper import Article\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
        "}\n",
        "\n",
        "article_url = \"https://www.artificialintelligence-news.com/2022/01/25/meta-claims-new-ai-supercomputer-will-set-records/\"\n",
        "\n",
        "session = requests.Session()\n",
        "\n",
        "\n",
        "try:\n",
        "    response = session.get(article_url, headers=headers, timeout=10)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        article = Article(article_url)\n",
        "        article.download()\n",
        "        article.parse()\n",
        "\n",
        "        print(f\"Title: {article.title}\")\n",
        "        print(f\"Text: {article.text}\")\n",
        "    else:\n",
        "        print(f\"Failed to fetch article at {article_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error occurred while fetching article at {article_url}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Mrx20THKYkA4"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import (\n",
        "    HumanMessage\n",
        ")\n",
        "\n",
        "# we get the article data from the scraping part\n",
        "article_title = article.title\n",
        "article_text = article.text\n",
        "\n",
        "# prepare template for prompt\n",
        "template = \"\"\"\n",
        "As an advanced AI, you've been tasked to summarize online articles into bulleted points. Here are a few examples of how you've done this in the past:\n",
        "\n",
        "Example 1:\n",
        "Original Article: 'The Effects of Climate Change\n",
        "Summary:\n",
        "- Climate change is causing a rise in global temperatures.\n",
        "- This leads to melting ice caps and rising sea levels.\n",
        "- Resulting in more frequent and severe weather conditions.\n",
        "\n",
        "Example 2:\n",
        "Original Article: 'The Evolution of Artificial Intelligence\n",
        "Summary:\n",
        "- Artificial Intelligence (AI) has developed significantly over the past decade.\n",
        "- AI is now used in multiple fields such as healthcare, finance, and transportation.\n",
        "- The future of AI is promising but requires careful regulation.\n",
        "\n",
        "Now, here's the article you need to summarize:\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "Please provide a summarized version of the article in a bulleted list format.\n",
        "\"\"\"\n",
        "\n",
        "# format prompt\n",
        "prompt = template.format(article_title=article.title, article_text=article.text)\n",
        "\n",
        "messages = [HumanMessage(content=prompt)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VomIzpn0uO_G"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# load the model\n",
        "chat = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCBiLvA-uO5X",
        "outputId": "7985fe43-9579-4e5b-dd5a-b143c42b586b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Meta (formerly Facebook) has announced the development of a new AI supercomputer named the AI Research SuperCluster (RSC).\n",
            "- The RSC is expected to be the world's fastest supercomputer upon its completion in mid-2022.\n",
            "- Currently, RSC is being used to train large natural language processing (NLP) and computer vision models.\n",
            "- Meta aims for the RSC to handle models with trillions of parameters and enhance capabilities such as real-time voice translations for diverse language groups.\n",
            "- The supercomputer is projected to be significantly faster than Meta's existing systems, with expectations of being 20x faster than their current V100-based clusters.\n",
            "- RSC will also improve the efficiency of training large-scale NLP workflows by three times.\n",
            "- The new infrastructure incorporates enhanced security and privacy controls, allowing the use of real-world data from Meta's production systems for training purposes.\n",
            "- This advancement will support Meta in tasks like identifying harmful content on its platforms more effectively.\n",
            "- Meta highlights the integration of performance, reliability, security, and privacy in RSC as a pioneering achievement in the field.\n"
          ]
        }
      ],
      "source": [
        "# generate summary\n",
        "summary = chat(messages)\n",
        "print(summary.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz2Et93TwvOs"
      },
      "source": [
        "# ======"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "afMNWcL9uOyG"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import validator\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "\n",
        "# create output parser class\n",
        "class ArticleSummary(BaseModel):\n",
        "    title: str = Field(description=\"Title of the article\")\n",
        "    summary: List[str] = Field(description=\"Bulleted list summary of the article\")\n",
        "\n",
        "    # validating whether the generated summary has at least three lines\n",
        "    @validator('summary')\n",
        "    def has_three_or_more_lines(cls, list_of_lines):\n",
        "        if len(list_of_lines) < 3:\n",
        "            raise ValueError(\"Generated summary has less than three bullet points!\")\n",
        "        return list_of_lines\n",
        "\n",
        "# set up output parser\n",
        "parser = PydanticOutputParser(pydantic_object=ArticleSummary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xutVrJsauOtJ"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "# create prompt template\n",
        "# notice that we are specifying the \"partial_variables\" parameter\n",
        "template = \"\"\"\n",
        "You are a very good assistant that summarizes online articles.\n",
        "\n",
        "Here's the article you want to summarize.\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"article_title\", \"article_text\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRJJc4r_uOlW",
        "outputId": "0056b405-2251-4b77-a3a9-a40c930bbf23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title='Meta claims its new AI supercomputer will set records' summary=[\"Meta (formerly Facebook) has unveiled an AI supercomputer called the AI Research SuperCluster (RSC) that it claims will be the world's fastest.\", 'RSC is set to be fully built in mid-2022 and will be capable of training models with trillions of parameters.', 'Meta aims to use RSC for tasks such as real-time voice translations and building technologies for the metaverse.', \"RSC is expected to be 20x faster than Meta's current clusters and 9x faster at running the NVIDIA Collective Communication Library (NCCL).\", 'Meta can now use real-world examples from its production systems for training AI models, including identifying harmful content on its platforms.']\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import LLMChain\n",
        "\n",
        "# instantiate model class\n",
        "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)\n",
        "\n",
        "chain = LLMChain(llm=model, prompt=prompt_template)\n",
        "\n",
        "# Run the LLMChain to get the AI-generated answer\n",
        "output = chain.run({\"article_title\": article_title, \"article_text\":article_text})\n",
        "\n",
        "# Parse the output into the Pydantic model\n",
        "parsed_output = parser.parse(output)\n",
        "print(parsed_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyRoqNMmxMqq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Geu-uFOGxlbQ"
      },
      "outputs": [],
      "source": [
        "parsed_output"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}